{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a59a655-02e0-4344-8b84-be96d86a1af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (0.1.7)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from langchain) (2.0.27)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from langchain) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from langchain) (0.6.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.20 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from langchain) (0.0.20)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.22 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from langchain) (0.1.23)\n",
      "Requirement already satisfied: langsmith<0.1,>=0.0.83 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from langchain) (0.0.87)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from langchain) (2.6.1)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: anyio<5,>=3 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from langchain-core<0.2,>=0.1.22->langchain) (4.2.0)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from langchain-core<0.2,>=0.1.22->langchain) (23.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (2.16.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.22->langchain) (1.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "756b2bed-59a8-483e-949d-b0ee1f4fcf49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-openai in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (0.0.6)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.16 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from langchain-openai) (0.1.23)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from langchain-openai) (1.26.4)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.10.0 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from langchain-openai) (1.12.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.5.2 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from langchain-openai) (0.6.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (6.0.1)\n",
      "Requirement already satisfied: anyio<5,>=3 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (4.2.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.0.88,>=0.0.87 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (0.0.87)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (2.6.1)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (8.2.3)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (0.26.0)\n",
      "Requirement already satisfied: sniffio in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.9.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from tiktoken<1,>=0.5.2->langchain-openai) (2023.12.25)\n",
      "Requirement already satisfied: idna>=2.8 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langchain-openai) (3.6)\n",
      "Requirement already satisfied: certifi in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (1.0.3)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1.16->langchain-openai) (2.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core<0.2,>=0.1.16->langchain-openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core<0.2,>=0.1.16->langchain-openai) (2.16.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from requests<3,>=2->langchain-core<0.2,>=0.1.16->langchain-openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from requests<3,>=2->langchain-core<0.2,>=0.1.16->langchain-openai) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f34bd07e-733a-4c28-86bf-c5bcc6df7914",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e5b1282-472f-4b22-8dc3-8b9a969a9a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Langsmith can help with testing in a few ways:\\n\\n1. Test automation: Langsmith can be used to automate the testing process, making it faster and more efficient. It can generate test scripts and run them automatically, saving time and reducing the chance of human error.\\n\\n2. Test data generation: Langsmith can generate test data for different scenarios, making it easier to test various use cases and edge cases. This can help ensure thorough test coverage and improve the overall quality of the testing process.\\n\\n3. Test case generation: Langsmith can generate test cases based on requirements or specifications, helping testers to quickly create test scenarios and ensure that all aspects of the software are thoroughly tested.\\n\\n4. Test result analysis: Langsmith can analyze test results and provide insights into the quality of the software being tested. It can help identify areas of improvement and provide recommendations for future testing efforts.\\n\\nOverall, Langsmith can help streamline the testing process, improve test coverage, and ultimately enhance the quality of the software being tested.')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"how can langsmith help with testing?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "373d7fed-3093-49ee-8873-da59a3302495",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are world class technical documentation writer.\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a27c1a7-167b-4d40-94cc-9748b1f325a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2eba42fb-88c7-462f-b7eb-ff377b9a1daf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Langsmith can help with testing in several ways:\\n\\n1. Automated Testing: Langsmith can generate test scripts and test data automatically, saving time and effort in writing and maintaining test cases.\\n\\n2. Test Coverage: Langsmith can analyze the codebase and identify areas that need more thorough testing, helping testers focus their efforts on critical areas.\\n\\n3. Test Case Generation: Langsmith can generate test cases based on code changes, ensuring that new features are thoroughly tested and existing functionality is not impacted.\\n\\n4. Regression Testing: Langsmith can automate regression testing, allowing testers to quickly verify that recent changes have not introduced any new bugs.\\n\\n5. Performance Testing: Langsmith can help testers simulate real-world usage scenarios and analyze the performance of the system under different load conditions.\\n\\nOverall, Langsmith can streamline the testing process, improve test coverage, and help identify and address issues more efficiently.')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"how can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a6d31df-59c3-40f6-a64f-c009db84485d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d9533d8-a6de-48df-8db8-3409e8431ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53386e9d-f653-4052-b4af-d0314a53ebef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Langsmith can greatly assist with testing by providing automated language verification and correction capabilities. By using Langsmith's language analysis and correction tools, testers can quickly identify any language-related issues in the software or documentation being tested. This can include spelling errors, grammatical mistakes, punctuation errors, and inconsistencies in language usage.\\n\\nAdditionally, Langsmith can help ensure that the language used in the software or documentation is clear, concise, and consistent, which is crucial for effective communication with end users. By using Langsmith to automate language testing, testers can save time and effort, improve the overall quality of the product, and enhance the user experience.\\n\\nOverall, Langsmith's language verification and correction capabilities can streamline the testing process, help identify and fix language-related issues, and contribute to the overall success of the testing efforts.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"how can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a676fbaf-6a59-4b58-9a5f-1112f7dbb45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from beautifulsoup4) (2.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac4629fe-e630-4c68-8d9d-63d15e68b5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com\")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58b34d77-9951-458c-a9fc-8652b1a08ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5bea8788-0187-4352-955a-f7fcaa59875c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (1.7.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f53a14e5-27c0-4a4c-9848-ea6f5bf87395",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "documents = text_splitter.split_documents(docs)\n",
    "vector = FAISS.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59687d31-1e5c-471b-99fb-90fe1331804b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Answer the following question based only on the provided context:\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {input}\"\"\")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56e51bda-4c5c-44e5-b6ae-029b1d74c7d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Langsmith can help visualize test results.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample test\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "document_chain.invoke({\n",
    "    \"input\": \"how can langsmith help with testing?\",\n",
    "    \"context\": [Document(page_content=\"langsmith can let you visualize test results\")]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "800c489b-610b-43ac-81b5-7466fe6fcf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5dcfc8d9-13a1-4c4a-986a-820cb53c922f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "retriever = vector.as_retriever()\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3bc4ef5c-e98a-4c09-a7b0-60e913516ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith can help with testing by allowing users to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. It provides tracing and evaluation capabilities, as well as seamless integration with LangChain, an open source framework for building with LLMs. Additionally, LangSmith offers a Prompt Hub, a prompt management tool built into the platform.\n"
     ]
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"how can langsmith help with testing?\"})\n",
    "print(response[\"answer\"])\n",
    "\n",
    "# LangSmith offers several features that can help with testing:..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8eb7629b-1fa4-4364-9956-f8da389330bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith can help with evaluation by providing a quick start guide for evaluating chains and intelligent agents built on any LLM framework. Additionally, LangSmith offers evaluation capabilities that allow users to test and assess the performance of their LLM applications.\n"
     ]
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"how can langsmith help with evaluation?\"})\n",
    "print(response[\"answer\"])\n",
    "\n",
    "# LangSmith offers several features that can help with testing:..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa66ec33-65f9-4983-a706-5d8d14167508",
   "metadata": {},
   "source": [
    "## Next - Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "019d9ad8-0114-477a-aadf-062dca7f041f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "# First we need a prompt that we can pass into an LLM to generate this search query\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "    (\"user\", \"Given the above conversation, generate a search query to look up in order to get information relevant to the conversation\")\n",
    "])\n",
    "retriever_chain = create_history_aware_retriever(llm, retriever, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "509b8a1a-c9fd-41d2-9d5c-b444d70e9892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith\\n\\n\\n\\n\\n\\nSkip to main contentü¶úÔ∏èüõ†Ô∏è LangSmith DocsLangChain Python DocsLangChain JS/TS DocsLangSmith API DocsSearchGo to AppLangSmithUser GuideSetupPricing (Coming Soon)Self-HostingTracingEvaluationMonitoringPrompt HubLangSmithOn this pageLangSmithIntroduction\\u200bLangSmith is a platform for building production-grade LLM applications.It lets you debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework and seamlessly integrates with LangChain, the go-to open source framework for building with LLMs.LangSmith is developed by LangChain, the company behind the open source LangChain framework.Quick Start\\u200bTracing: Get started with the tracing quick start.Evaluation: Get started with the evaluation quick start.Next Steps\\u200bCheck out the following sections to learn more about LangSmith:User Guide: Learn about the workflows LangSmith supports at each stage of the LLM application lifecycle.Setup: Learn how to create an account, obtain an API key, and configure your environment.Pricing: Learn about the pricing model for LangSmith.Self-Hosting: Learn about self-hosting options for LangSmith.Tracing: Learn about the tracing capabilities of LangSmith.Evaluation: Learn about the evaluation capabilities of LangSmith.Prompt Hub Learn about the Prompt Hub, a prompt management tool built into LangSmith.Additional Resources\\u200bLangSmith Cookbook: A collection of tutorials and end-to-end walkthroughs using LangSmith.LangChain Python: Docs for the Python LangChain library.LangChain Python API Reference: documentation to review the core APIs of LangChain.LangChain JS: Docs for the TypeScript LangChain libraryDiscord: Join us on our Discord to discuss all things LangChain!Contact SalesIf you're interested in enterprise security and admin features, special deployment options, or access for large teams, reach out to speak with sales.NextUser GuideIntroductionQuick StartNext StepsAdditional ResourcesCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogCopyright ¬© 2024 LangChain, Inc.\", metadata={'source': 'https://docs.smith.langchain.com', 'title': 'LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith', 'description': 'Introduction', 'language': 'en'})]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "chat_history = [HumanMessage(content=\"Can LangSmith help test my LLM applications?\"), AIMessage(content=\"Yes!\")]\n",
    "retriever_chain.invoke({\n",
    "    \"chat_history\": chat_history,\n",
    "    \"input\": \"Tell me how\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabbf215-0c72-4fd0-9dd7-fd6bfbc94435",
   "metadata": {},
   "source": [
    "You should see that this returns documents about testing in LangSmith. This is because the LLM generated a new query, combining the chat history with the follow up question.\r\n",
    "\r\n",
    "Now that we have this new retriever, we can create a new chain to continue the conversation with these retrieved documents in mind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ed5fd6c-d13e-4b7f-9cd7-4c22179e7881",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Answer the user's questions based on the below context:\\n\\n{context}\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "])\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "retrieval_chain = create_retrieval_chain(retriever_chain, document_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f60ab3-588d-4af9-b184-1dc400eb005b",
   "metadata": {},
   "source": [
    "We can now test this out end-to-end:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b483800a-2b3c-4ac9-ad61-560b3beefcfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='Can LangSmith help test my LLM applications?'),\n",
       "  AIMessage(content='Yes!')],\n",
       " 'input': 'Tell me how',\n",
       " 'context': [Document(page_content=\"LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith\\n\\n\\n\\n\\n\\nSkip to main contentü¶úÔ∏èüõ†Ô∏è LangSmith DocsLangChain Python DocsLangChain JS/TS DocsLangSmith API DocsSearchGo to AppLangSmithUser GuideSetupPricing (Coming Soon)Self-HostingTracingEvaluationMonitoringPrompt HubLangSmithOn this pageLangSmithIntroduction\\u200bLangSmith is a platform for building production-grade LLM applications.It lets you debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework and seamlessly integrates with LangChain, the go-to open source framework for building with LLMs.LangSmith is developed by LangChain, the company behind the open source LangChain framework.Quick Start\\u200bTracing: Get started with the tracing quick start.Evaluation: Get started with the evaluation quick start.Next Steps\\u200bCheck out the following sections to learn more about LangSmith:User Guide: Learn about the workflows LangSmith supports at each stage of the LLM application lifecycle.Setup: Learn how to create an account, obtain an API key, and configure your environment.Pricing: Learn about the pricing model for LangSmith.Self-Hosting: Learn about self-hosting options for LangSmith.Tracing: Learn about the tracing capabilities of LangSmith.Evaluation: Learn about the evaluation capabilities of LangSmith.Prompt Hub Learn about the Prompt Hub, a prompt management tool built into LangSmith.Additional Resources\\u200bLangSmith Cookbook: A collection of tutorials and end-to-end walkthroughs using LangSmith.LangChain Python: Docs for the Python LangChain library.LangChain Python API Reference: documentation to review the core APIs of LangChain.LangChain JS: Docs for the TypeScript LangChain libraryDiscord: Join us on our Discord to discuss all things LangChain!Contact SalesIf you're interested in enterprise security and admin features, special deployment options, or access for large teams, reach out to speak with sales.NextUser GuideIntroductionQuick StartNext StepsAdditional ResourcesCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogCopyright ¬© 2024 LangChain, Inc.\", metadata={'source': 'https://docs.smith.langchain.com', 'title': 'LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith', 'description': 'Introduction', 'language': 'en'})],\n",
       " 'answer': 'LangSmith can help test your LLM applications by providing a platform for debugging, testing, evaluating, and monitoring chains and intelligent agents built on any LLM framework. It seamlessly integrates with LangChain, an open-source framework for building with LLMs. You can use LangSmith to trace and evaluate your applications, ensuring they meet your requirements and perform as expected.'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history = [HumanMessage(content=\"Can LangSmith help test my LLM applications?\"), AIMessage(content=\"Yes!\")]\n",
    "retrieval_chain.invoke({\n",
    "    \"chat_history\": chat_history,\n",
    "    \"input\": \"Tell me how\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076bd39e-7ea8-40e6-8979-ec252aa269ab",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab55cf09-d193-476b-907a-cca4cd45b1e4",
   "metadata": {},
   "source": [
    "[Getting Started](https://python.langchain.com/docs/get_started/quickstart#jupyter-notebook)\n",
    "We've so far create examples of chains - where each step is known ahead of time. The final thing we will create is an agent - where the LLM decides what steps to take.\r\n",
    "\r\n",
    "NOTE: for this example we will only show how to create an agent using OpenAI models, as local models are not reliable enough yet.\r\n",
    "\r\n",
    "One of the first things to do when building an agent is to decide what tools it should have access to. For this example, we will give the agent access two tools:\r\n",
    "\r\n",
    "The retriever we just created. This will let it easily answer questions about LangSmith\r\n",
    "A search tool. This will let it easily answer questions that require up to date information.\r\n",
    "First, let's set up a tool for the retriever we just created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a8752fc-9e24-4967-bdf2-174696714029",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"langsmith_search\",\n",
    "    \"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b6183da2-eee9-41bf-aecf-fe5dc50d5217",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "search = TavilySearchResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2041ae32-5883-43ff-a7f6-c41f66ab0fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [retriever_tool, search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5214900-31bb-4423-a1dc-42ff806102e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchainhub in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (0.1.14)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from langchainhub) (2.31.0)\n",
      "Requirement already satisfied: types-requests<3.0.0.0,>=2.31.0.2 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from langchainhub) (2.31.0.20240125)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from requests<3,>=2->langchainhub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from requests<3,>=2->langchainhub) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from requests<3,>=2->langchainhub) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mike/.local/share/virtualenvs/pytorchcuda-JwL-obOK/lib/python3.11/site-packages (from requests<3,>=2->langchainhub) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchainhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1cfd252d-f47a-40d8-9b0d-7daeb03bc4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import hub\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "from langchain.agents import AgentExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "89ab1eb5-393f-475f-9a06-0b8ec9d72436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import requests\n",
    "#requests.get(url, headers=Hostreferer,verify=False)\n",
    "# Get the prompt to use - you can modify this!\n",
    "#https://api.hub.langchain.com/commits/oshea00/openai-functions-agent/?limit=100&offset=0\n",
    "#from https://www.langchain.com/langchain\n",
    "prompt = hub.pull(\"oshea00/openai-functions-agent\")\n",
    "prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fcfade56-e926-4b68-9e86-a7d7e278425a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "87f1e4db-6bf3-4b78-a0e8-54c957eb0154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8a367dc4-bfd2-45eb-b84d-381e63eb5d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langsmith_search` with `{'query': 'how can LangSmith help with testing'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mLangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Skip to main contentü¶úÔ∏èüõ†Ô∏è LangSmith DocsLangChain Python DocsLangChain JS/TS DocsLangSmith API DocsSearchGo to AppLangSmithUser GuideSetupPricing (Coming Soon)Self-HostingTracingEvaluationMonitoringPrompt HubLangSmithOn this pageLangSmithIntroduction‚ÄãLangSmith is a platform for building production-grade LLM applications.It lets you debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework and seamlessly integrates with LangChain, the go-to open source framework for building with LLMs.LangSmith is developed by LangChain, the company behind the open source LangChain framework.Quick Start‚ÄãTracing: Get started with the tracing quick start.Evaluation: Get started with the evaluation quick start.Next Steps‚ÄãCheck out the following sections to learn more about LangSmith:User Guide: Learn about the workflows LangSmith supports at each stage of the LLM application lifecycle.Setup: Learn how to create an account, obtain an API key, and configure your environment.Pricing: Learn about the pricing model for LangSmith.Self-Hosting: Learn about self-hosting options for LangSmith.Tracing: Learn about the tracing capabilities of LangSmith.Evaluation: Learn about the evaluation capabilities of LangSmith.Prompt Hub Learn about the Prompt Hub, a prompt management tool built into LangSmith.Additional Resources‚ÄãLangSmith Cookbook: A collection of tutorials and end-to-end walkthroughs using LangSmith.LangChain Python: Docs for the Python LangChain library.LangChain Python API Reference: documentation to review the core APIs of LangChain.LangChain JS: Docs for the TypeScript LangChain libraryDiscord: Join us on our Discord to discuss all things LangChain!Contact SalesIf you're interested in enterprise security and admin features, special deployment options, or access for large teams, reach out to speak with sales.NextUser GuideIntroductionQuick StartNext StepsAdditional ResourcesCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogCopyright ¬© 2024 LangChain, Inc.\u001b[0m\u001b[32;1m\u001b[1;3mLangSmith is a platform for building production-grade LLM (Large Language Model) applications. It can help with testing by allowing you to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. LangSmith seamlessly integrates with LangChain, which is an open-source framework for building with LLMs. \n",
      "\n",
      "You can use LangSmith for tracing, evaluation, and monitoring your LLM applications. It provides capabilities for tracing and evaluating the performance of your models. Additionally, LangSmith offers a Prompt Hub, which is a prompt management tool built into the platform.\n",
      "\n",
      "If you want to learn more about how LangSmith can specifically assist with testing, you can explore the User Guide, Setup, Pricing, and Self-Hosting sections on the LangSmith platform.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'how can langsmith help with testing?',\n",
       " 'output': 'LangSmith is a platform for building production-grade LLM (Large Language Model) applications. It can help with testing by allowing you to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. LangSmith seamlessly integrates with LangChain, which is an open-source framework for building with LLMs. \\n\\nYou can use LangSmith for tracing, evaluation, and monitoring your LLM applications. It provides capabilities for tracing and evaluating the performance of your models. Additionally, LangSmith offers a Prompt Hub, which is a prompt management tool built into the platform.\\n\\nIf you want to learn more about how LangSmith can specifically assist with testing, you can explore the User Guide, Setup, Pricing, and Self-Hosting sections on the LangSmith platform.'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"how can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b1559462-a0aa-4bf3-9167-443017e36b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'weather in Seattle'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m[{'url': 'https://www.accuweather.com/en/us/seattle/98104/weather-forecast/351409', 'content': 'Get the current weather, air quality, wind speed and direction, and pollen levels for Seattle, WA. See the hourly, daily, and monthly forecasts for temperature, precipitation, and UV index. Find out the health and activity recommendations for sensitive groups and outdoor activities.'}, {'url': 'https://forecast.weather.gov/zipcity.php?inputstring=Seattle,WA', 'content': 'Lat: 47.54548¬∞N Lon: 122.3147¬∞W Elev: 20.0ft. Mostly Cloudy 36¬∞F 2¬∞C More Information: Local Forecast Office More Local Wx 3 Day History Mobile Weather Hourly Weather Forecast Extended Forecast for Seattle WA Similar City Names Overnight Mostly Cloudy Low: 38 ¬∞F Saturday Partly Sunny High: 49 ¬∞F Saturday Night Chance Rain Low: 43 ¬∞F Sunday Rain'}, {'url': 'https://weather.com/weather/tenday/l/Seattle+WA?canonicalCityId=0795df0bbf6ddfe58c10abd8ce5ed2a901e48b13b3ee35d10cb229baff15ed15', 'content': 'Low 37F. Winds light and variable. Humidity 87% UV Index 0 of 11 Moonrise 7:48 am New Moon Moonset 5:09 pm Sat 10 49¬∞/ 42¬∞ 8% Sun 11 50¬∞/ 43¬∞ 70% Mon 12 50¬∞/ 38¬∞ 23% Tue 13 49¬∞/ 37¬∞'}, {'url': 'https://www.wunderground.com/forecast/us/wa/seattle', 'content': 'Find the current weather conditions and forecast for Seattle, WA from Weather Underground, a trusted source of local and long-range weather information. See the hourly, daily and 10-day outlook for temperature, precipitation, wind, humidity and more.'}, {'url': 'https://weather.com/weather/today/l/Seattle+WA?canonicalCityId=0795df0bbf6ddfe58c10abd8ce5ed2a901e48b13b3ee35d10cb229baff15ed15', 'content': 'Weather Forecast and Conditions for Seattle, WA - The Weather Channel | Weather.com Seattle, WA As of 2:17 am PST 43¬∞ Cloudy Day 47¬∞ ‚Ä¢ Night 39¬∞ Watch: Avalanche At Nevada Ski Resort...'}]\u001b[0m\u001b[32;1m\u001b[1;3mThe current weather in Seattle is mostly cloudy with a temperature of 36¬∞F. The forecast for the next few days includes partly sunny weather with temperatures ranging from 38¬∞F to 50¬∞F. You can find more detailed information on [AccuWeather](https://www.accuweather.com/en/us/seattle/98104/weather-forecast/351409) or [Weather.com](https://weather.com/weather/tenday/l/Seattle+WA?canonicalCityId=0795df0bbf6ddfe58c10abd8ce5ed2a901e48b13b3ee35d10cb229baff15ed15).\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is the weather in Seattle?',\n",
       " 'output': 'The current weather in Seattle is mostly cloudy with a temperature of 36¬∞F. The forecast for the next few days includes partly sunny weather with temperatures ranging from 38¬∞F to 50¬∞F. You can find more detailed information on [AccuWeather](https://www.accuweather.com/en/us/seattle/98104/weather-forecast/351409) or [Weather.com](https://weather.com/weather/tenday/l/Seattle+WA?canonicalCityId=0795df0bbf6ddfe58c10abd8ce5ed2a901e48b13b3ee35d10cb229baff15ed15).'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "agent_executor.invoke({\"input\": \"what is the weather in Seattle?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bbe7709a-107b-4395-a131-cd6fdbf0814b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langsmith_search` with `{'query': 'LangSmith LLM application testing services'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mLangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Skip to main contentü¶úÔ∏èüõ†Ô∏è LangSmith DocsLangChain Python DocsLangChain JS/TS DocsLangSmith API DocsSearchGo to AppLangSmithUser GuideSetupPricing (Coming Soon)Self-HostingTracingEvaluationMonitoringPrompt HubLangSmithOn this pageLangSmithIntroduction‚ÄãLangSmith is a platform for building production-grade LLM applications.It lets you debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework and seamlessly integrates with LangChain, the go-to open source framework for building with LLMs.LangSmith is developed by LangChain, the company behind the open source LangChain framework.Quick Start‚ÄãTracing: Get started with the tracing quick start.Evaluation: Get started with the evaluation quick start.Next Steps‚ÄãCheck out the following sections to learn more about LangSmith:User Guide: Learn about the workflows LangSmith supports at each stage of the LLM application lifecycle.Setup: Learn how to create an account, obtain an API key, and configure your environment.Pricing: Learn about the pricing model for LangSmith.Self-Hosting: Learn about self-hosting options for LangSmith.Tracing: Learn about the tracing capabilities of LangSmith.Evaluation: Learn about the evaluation capabilities of LangSmith.Prompt Hub Learn about the Prompt Hub, a prompt management tool built into LangSmith.Additional Resources‚ÄãLangSmith Cookbook: A collection of tutorials and end-to-end walkthroughs using LangSmith.LangChain Python: Docs for the Python LangChain library.LangChain Python API Reference: documentation to review the core APIs of LangChain.LangChain JS: Docs for the TypeScript LangChain libraryDiscord: Join us on our Discord to discuss all things LangChain!Contact SalesIf you're interested in enterprise security and admin features, special deployment options, or access for large teams, reach out to speak with sales.NextUser GuideIntroductionQuick StartNext StepsAdditional ResourcesCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogCopyright ¬© 2024 LangChain, Inc.\u001b[0m\u001b[32;1m\u001b[1;3mLangSmith is a platform for building production-grade LLM applications. It allows you to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. LangSmith seamlessly integrates with LangChain, the open-source framework for building with LLMs. You can learn more about LangSmith by checking out their user guide, setup instructions, pricing, self-hosting options, tracing capabilities, evaluation capabilities, and the Prompt Hub. If you are interested in testing your LLM applications, LangSmith can be a valuable tool for that purpose.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='Can LangSmith help test my LLM applications?'),\n",
       "  AIMessage(content='Yes!')],\n",
       " 'input': 'Tell me how',\n",
       " 'output': 'LangSmith is a platform for building production-grade LLM applications. It allows you to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. LangSmith seamlessly integrates with LangChain, the open-source framework for building with LLMs. You can learn more about LangSmith by checking out their user guide, setup instructions, pricing, self-hosting options, tracing capabilities, evaluation capabilities, and the Prompt Hub. If you are interested in testing your LLM applications, LangSmith can be a valuable tool for that purpose.'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history = [HumanMessage(content=\"Can LangSmith help test my LLM applications?\"), AIMessage(content=\"Yes!\")]\n",
    "agent_executor.invoke({\n",
    "    \"chat_history\": chat_history,\n",
    "    \"input\": \"Tell me how\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5cf304-6eea-4345-8153-efb95ce03c09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
